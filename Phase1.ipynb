{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6835015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from pyturk.datasets import MSCTD\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, ToPILImage\n",
    "from prime_augmentations.utils.rand_filter import RandomFilter\n",
    "from prime_augmentations.utils.color_jitter import RandomSmoothColor\n",
    "from prime_augmentations.utils.diffeomorphism import Diffeo\n",
    "from prime_augmentations.config import imagenet100_cfg\n",
    "from random import choice\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8687980a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74d775",
   "metadata": {},
   "source": [
    "### 1-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "928615df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:opening and reading files...\n",
      "INFO:root:opening and reading files...\n"
     ]
    }
   ],
   "source": [
    "# load train, dev and test datasets\n",
    "\n",
    "train_dataset_orig = MSCTD(\n",
    "    root='data',\n",
    "    mode='train',\n",
    "    download=False,\n",
    "    cnn_mode=True,\n",
    "    image_transform=Compose([\n",
    "        Resize((64, 128)),\n",
    "        ToTensor(),\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_dataset_orig = MSCTD(\n",
    "    root='data',\n",
    "    mode='test',\n",
    "    download=False,\n",
    "    cnn_mode=True,\n",
    "    image_transform=Compose([\n",
    "        Resize((64, 128)),\n",
    "        ToTensor(),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26549e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_tensor = ToTensor()\n",
    "\n",
    "def input_transform(img):\n",
    "    img = img.resize((128, 128))\n",
    "    return transform_to_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db2c25c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract faces from training set\n",
    "# images_dir_path_train = train_dataset_orig.extract_faces()\n",
    "images_dir_path_train = './data/MSCTD/faces/train'\n",
    "train_dataset = ImageFolder(root=images_dir_path_train, transform=input_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d279037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract faces from test set\n",
    "# images_dir_path_test = test_dataset_orig.extract_faces()\n",
    "images_dir_path_test = './data/MSCTD/faces/test'\n",
    "test_dataset = ImageFolder(root=images_dir_path_test, transform=input_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3111f1",
   "metadata": {},
   "source": [
    "### 1-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0da92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 16, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(16, 4, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(49*4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.mlp_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc260c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671d7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd5945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61948841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4426cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "train_loss: 1.0411368608474731\n",
      "Train Accuracy: 37.28%\n",
      "Test Accuracy: 40.02%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "train_loss: 1.041334629058838\n",
      "Train Accuracy: 37.94%\n",
      "Test Accuracy: 38.35%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "train_loss: 1.0953128337860107\n",
      "Train Accuracy: 38.87%\n",
      "Test Accuracy: 37.72%\n",
      "\n",
      "epoch 4 ==================================================\n",
      "train_loss: 1.0574090480804443\n",
      "Train Accuracy: 39.21%\n",
      "Test Accuracy: 37.39%\n",
      "\n",
      "epoch 5 ==================================================\n",
      "train_loss: 1.1481467485427856\n",
      "Train Accuracy: 39.61%\n",
      "Test Accuracy: 36.99%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1672318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./Models/first_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08bc82",
   "metadata": {},
   "source": [
    "### 1-1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38566ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize MTCNN face detector\n",
    "mtcnn = MTCNN(\n",
    "    device=device,\n",
    "    select_largest=False,\n",
    "    post_process=False,\n",
    "    margin=50,\n",
    "    keep_all=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e3ba6a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9038d67fb164c49a52bccd09c921dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 35.879 %\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "to_pil_image = ToPILImage()\n",
    "\n",
    "for img, label in tqdm(test_dataset_orig):\n",
    "    img = to_pil_image(img)\n",
    "    faces = mtcnn(img)\n",
    "    true_label = torch.tensor(label).to(device)\n",
    "    if faces is None:\n",
    "        # if there is no face in the image, label it as negative (the class with most data)\n",
    "        num_correct += (1 == true_label).sum().item()\n",
    "        continue\n",
    "    estimated_labels = []\n",
    "    for face in faces:\n",
    "        face = face.permute(1, 2, 0)  \n",
    "        face = torch.tensor(cv2.resize(face.numpy(), (128, 128)))\n",
    "        face = face.to(device) / 255\n",
    "        face = face.permute(2, 1, 0)\n",
    "        face = face.reshape(1, *face.shape)\n",
    "        y_pred = model(face).flatten()\n",
    "        estimated_labels.append(y_pred.argmax().cpu().item())\n",
    "    most_voted_label = np.bincount(estimated_labels).argmax()\n",
    "    num_correct += (most_voted_label == true_label).sum().item()\n",
    "    \n",
    "print(f'accuracy: {np.round(num_correct * 100 / len(test_dataset_orig), 3) } %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57230ec",
   "metadata": {},
   "source": [
    "### 1-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8573c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = imagenet100_cfg.get_config()\n",
    "\n",
    "diffeo = Diffeo(\n",
    "    sT=config.diffeo.sT, rT=config.diffeo.rT,\n",
    "    scut=config.diffeo.scut, rcut=config.diffeo.rcut,\n",
    "    cutmin=config.diffeo.cutmin, cutmax=config.diffeo.cutmax,\n",
    "    alpha=config.diffeo.alpha, stochastic=True\n",
    ")\n",
    "\n",
    "color = RandomSmoothColor(\n",
    "    cut=config.color_jit.cut, T=config.color_jit.T,\n",
    "    freq_bandwidth=config.color_jit.max_freqs, stochastic=True\n",
    ")\n",
    "\n",
    "filt = RandomFilter(\n",
    "    kernel_size=3,\n",
    "    sigma=1,\n",
    "    stochastic=True\n",
    ")\n",
    "\n",
    "identical = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7531a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform_aug_only(x):\n",
    "    transforms = [diffeo, color, filt]\n",
    "    x = input_transform(x)\n",
    "    random_transform = choice(transforms)\n",
    "    x = random_transform(x)\n",
    "    return x\n",
    "\n",
    "images_dir_path_test = './data/MSCTD/faces/test'\n",
    "test_dataset_aug_only = ImageFolder(\n",
    "    root=images_dir_path_test,\n",
    "    transform = custom_transform_aug_only\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc607e1",
   "metadata": {},
   "source": [
    "### 1-2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "258b7657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 38.24%\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "test_dataloader = DataLoader(test_dataset_aug_only, batch_size=batch_size, shuffle=False)\n",
    "test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a43ffa",
   "metadata": {},
   "source": [
    "### 1-2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26af1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform_aug_with_identical(x):\n",
    "    transforms = [identical, diffeo, color, filt]\n",
    "    x = input_transform(x)\n",
    "    random_transform = choice(transforms)\n",
    "    x = random_transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d67e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract faces from training set\n",
    "images_dir_path_train = './data/MSCTD/faces/train'\n",
    "train_dataset_aug_with_identical = ImageFolder(\n",
    "    root=images_dir_path_train,\n",
    "    transform = custom_transform_aug_with_identical\n",
    ")\n",
    "\n",
    "images_dir_path_test = './data/MSCTD/faces/test'\n",
    "test_dataset_aug_with_identical = ImageFolder(\n",
    "    root=images_dir_path_test,\n",
    "    transform = custom_transform_aug_with_identical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f84016e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 16, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(16, 4, kernel_size=3, stride=1, padding='same'),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(49*4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = self.mlp_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55cdb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = CNNNetwork2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1bb8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "learning_rate = 5e-3\n",
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d786e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)\n",
    "train_dataloader = DataLoader(train_dataset_aug_with_identical, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset_aug_with_identical, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ce8029c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "train_loss: 1.0971670150756836\n",
      "Train Accuracy: 37.07%\n",
      "Test Accuracy: 39.99%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "train_loss: 1.1271135807037354\n",
      "Train Accuracy: 37.19%\n",
      "Test Accuracy: 40.97%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "train_loss: 1.0743521451950073\n",
      "Train Accuracy: 37.14%\n",
      "Test Accuracy: 40.97%\n",
      "\n",
      "epoch 4 ==================================================\n",
      "train_loss: 1.0734622478485107\n",
      "Train Accuracy: 37.21%\n",
      "Test Accuracy: 40.97%\n",
      "\n",
      "epoch 5 ==================================================\n",
      "train_loss: 1.0424246788024902\n",
      "Train Accuracy: 37.21%\n",
      "Test Accuracy: 40.97%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model2, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model2, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46a8e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2, \"./Models/second_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5da7e6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 40.97%\n"
     ]
    }
   ],
   "source": [
    "# test the network using original data\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08d9c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 40.97%\n"
     ]
    }
   ],
   "source": [
    "# test the network using augmented data\n",
    "test_dataloader = DataLoader(test_dataset_aug_only, batch_size=batch_size, shuffle=False)\n",
    "test_loop(test_dataloader, model2, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff3307",
   "metadata": {},
   "source": [
    "### 2-1-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9df3ed",
   "metadata": {},
   "source": [
    "We are using resnet50 for this part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e270f8",
   "metadata": {},
   "source": [
    "### 2-1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2d4593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7bf81ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# structure of the network\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ab877b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change last fully connected layer\n",
    "in_features = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 1024),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 3)\n",
    ")\n",
    "pretrained_model = pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc788a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0045,  0.0064,  0.0001,  ..., -0.0054,  0.0030, -0.0128],\n",
       "         [-0.0087,  0.0171, -0.0170,  ...,  0.0041,  0.0166,  0.0183],\n",
       "         [ 0.0179,  0.0165, -0.0047,  ...,  0.0098,  0.0206,  0.0048],\n",
       "         ...,\n",
       "         [ 0.0030, -0.0191, -0.0116,  ...,  0.0013,  0.0199, -0.0038],\n",
       "         [-0.0038,  0.0114, -0.0010,  ..., -0.0176,  0.0057, -0.0130],\n",
       "         [ 0.0103, -0.0024, -0.0207,  ...,  0.0196,  0.0200, -0.0021]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0047,  0.0218,  0.0210,  ..., -0.0168, -0.0140, -0.0183],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0223, -0.0301, -0.0159,  ..., -0.0305, -0.0016,  0.0172],\n",
       "         [ 0.0255, -0.0121,  0.0093,  ...,  0.0223,  0.0100,  0.0173],\n",
       "         [ 0.0221,  0.0265, -0.0075,  ..., -0.0092,  0.0224, -0.0217],\n",
       "         ...,\n",
       "         [-0.0047, -0.0084, -0.0246,  ...,  0.0121, -0.0226,  0.0131],\n",
       "         [ 0.0239, -0.0295, -0.0210,  ...,  0.0078, -0.0228,  0.0309],\n",
       "         [ 0.0055, -0.0229,  0.0295,  ..., -0.0260,  0.0134, -0.0109]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0179,  0.0278, -0.0140, -0.0109, -0.0085,  0.0047,  0.0195, -0.0108,\n",
       "          0.0129,  0.0009,  0.0020,  0.0170,  0.0269,  0.0233, -0.0163,  0.0009,\n",
       "          0.0186, -0.0294, -0.0225,  0.0131, -0.0129, -0.0312,  0.0288, -0.0218,\n",
       "         -0.0022, -0.0128,  0.0122, -0.0070, -0.0267, -0.0223,  0.0102, -0.0211,\n",
       "         -0.0207,  0.0302,  0.0064, -0.0028,  0.0206, -0.0176,  0.0151,  0.0008,\n",
       "          0.0132,  0.0031, -0.0014, -0.0192, -0.0121, -0.0211, -0.0295,  0.0221,\n",
       "         -0.0015, -0.0266,  0.0150,  0.0227, -0.0039,  0.0251,  0.0297,  0.0242,\n",
       "         -0.0254,  0.0253, -0.0068, -0.0011, -0.0240,  0.0214,  0.0221,  0.0311,\n",
       "          0.0107, -0.0233, -0.0028, -0.0267,  0.0134,  0.0071, -0.0298, -0.0259,\n",
       "         -0.0120, -0.0232, -0.0205,  0.0249,  0.0067, -0.0247, -0.0070,  0.0299,\n",
       "          0.0111, -0.0065, -0.0022, -0.0163,  0.0250, -0.0273,  0.0125, -0.0063,\n",
       "         -0.0292,  0.0247, -0.0258, -0.0118, -0.0286,  0.0104,  0.0023, -0.0211,\n",
       "          0.0140, -0.0283, -0.0307, -0.0032, -0.0289, -0.0026, -0.0260,  0.0116,\n",
       "         -0.0184, -0.0265,  0.0134,  0.0037, -0.0067,  0.0228,  0.0152, -0.0263,\n",
       "         -0.0100,  0.0262,  0.0145,  0.0129, -0.0049,  0.0002,  0.0159,  0.0126,\n",
       "          0.0214, -0.0237, -0.0137,  0.0093,  0.0212,  0.0202,  0.0092,  0.0142,\n",
       "         -0.0280,  0.0143, -0.0072, -0.0107,  0.0260,  0.0089,  0.0070, -0.0164,\n",
       "         -0.0029, -0.0211,  0.0297,  0.0096,  0.0033,  0.0020,  0.0185,  0.0040,\n",
       "          0.0238, -0.0141,  0.0285,  0.0145, -0.0223, -0.0248,  0.0302,  0.0156,\n",
       "          0.0098,  0.0187, -0.0248,  0.0057, -0.0062, -0.0304, -0.0056, -0.0246,\n",
       "          0.0090, -0.0088, -0.0063, -0.0268, -0.0274, -0.0065, -0.0264, -0.0002,\n",
       "         -0.0130, -0.0012,  0.0251,  0.0271, -0.0275,  0.0092, -0.0082, -0.0117,\n",
       "         -0.0255,  0.0158,  0.0246, -0.0181, -0.0025,  0.0163,  0.0258,  0.0166,\n",
       "          0.0302,  0.0079,  0.0026,  0.0232,  0.0294,  0.0039, -0.0033,  0.0163,\n",
       "          0.0305,  0.0291, -0.0254,  0.0195,  0.0252, -0.0194,  0.0161,  0.0298,\n",
       "          0.0204,  0.0285, -0.0112, -0.0119, -0.0131, -0.0276, -0.0052, -0.0090,\n",
       "          0.0048,  0.0154, -0.0092, -0.0220, -0.0205, -0.0292,  0.0035,  0.0104,\n",
       "         -0.0064,  0.0122,  0.0007, -0.0071, -0.0167,  0.0158,  0.0085,  0.0283,\n",
       "          0.0189, -0.0050,  0.0143,  0.0210,  0.0240,  0.0014,  0.0087,  0.0140,\n",
       "         -0.0177, -0.0302, -0.0139,  0.0038, -0.0169,  0.0042, -0.0165, -0.0165,\n",
       "         -0.0116, -0.0256,  0.0260,  0.0108,  0.0269,  0.0013, -0.0310, -0.0235,\n",
       "          0.0235, -0.0166, -0.0147, -0.0018, -0.0116, -0.0014, -0.0129, -0.0203],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0477,  0.0337, -0.0177,  ..., -0.0216, -0.0390,  0.0379],\n",
       "         [-0.0468,  0.0018,  0.0604,  ...,  0.0144,  0.0615, -0.0493],\n",
       "         [ 0.0107,  0.0454, -0.0232,  ...,  0.0269, -0.0231, -0.0165],\n",
       "         ...,\n",
       "         [-0.0245, -0.0521, -0.0611,  ...,  0.0056,  0.0022,  0.0597],\n",
       "         [ 0.0616, -0.0541,  0.0525,  ...,  0.0196,  0.0126,  0.0502],\n",
       "         [ 0.0592,  0.0408,  0.0519,  ..., -0.0099, -0.0309,  0.0356]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0446,  0.0249,  0.0355,  0.0295, -0.0233, -0.0348,  0.0442, -0.0317,\n",
       "          0.0297,  0.0540,  0.0441, -0.0222,  0.0402, -0.0591,  0.0061, -0.0134,\n",
       "         -0.0188, -0.0220,  0.0580,  0.0577, -0.0162,  0.0111,  0.0019,  0.0076,\n",
       "          0.0253, -0.0144,  0.0109, -0.0205, -0.0523, -0.0439,  0.0238,  0.0617,\n",
       "          0.0577,  0.0141, -0.0437,  0.0330, -0.0355,  0.0594, -0.0129, -0.0137,\n",
       "         -0.0133,  0.0087, -0.0493, -0.0601,  0.0376,  0.0248,  0.0006,  0.0277,\n",
       "         -0.0219, -0.0342, -0.0590, -0.0008, -0.0030,  0.0554, -0.0283, -0.0406,\n",
       "         -0.0621,  0.0032,  0.0181,  0.0269, -0.0622,  0.0460, -0.0132,  0.0117],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.1238e-01, -2.2116e-03,  6.0629e-02, -8.4359e-02,  1.1172e-01,\n",
       "          -5.2350e-02, -8.5358e-02, -2.7161e-02, -1.8406e-02, -1.0183e-01,\n",
       "           1.0052e-01, -8.4099e-02,  9.5404e-02,  8.2573e-02, -7.8826e-02,\n",
       "          -4.4181e-02, -6.5163e-02, -6.6243e-02, -2.4394e-02, -2.3684e-02,\n",
       "          -5.5382e-02, -7.5947e-02,  8.4696e-03,  3.4366e-02,  2.1819e-03,\n",
       "           1.0016e-01,  3.2944e-02, -1.0725e-01,  2.2375e-02,  2.3937e-02,\n",
       "          -4.5122e-02,  3.8840e-02, -4.4518e-02,  1.6920e-02, -7.9605e-02,\n",
       "           7.8405e-02, -2.1399e-02, -4.8590e-02, -5.5215e-02,  3.3097e-02,\n",
       "           6.7630e-03,  6.3350e-02,  3.4064e-02, -3.2235e-02,  4.2414e-02,\n",
       "           7.8758e-02, -2.4113e-02, -5.6349e-02,  2.8400e-02, -1.2061e-01,\n",
       "           8.9292e-02, -7.7818e-02,  1.2360e-01, -5.5791e-02,  8.5463e-02,\n",
       "           9.2167e-02, -8.5441e-02,  2.7112e-02, -2.6918e-02,  4.4886e-02,\n",
       "           2.0508e-02,  5.5155e-02,  1.0907e-01,  2.0223e-02],\n",
       "         [-6.7435e-02, -4.1153e-02,  7.9830e-02,  1.1910e-01,  1.6308e-02,\n",
       "          -1.8772e-02,  5.6297e-03, -1.1393e-01, -9.3669e-02, -6.5032e-02,\n",
       "           1.0580e-01, -3.6703e-02, -3.9032e-02, -6.9434e-02, -1.1921e-01,\n",
       "          -1.2150e-04, -1.1688e-02,  3.5129e-02, -8.2261e-02, -8.7909e-02,\n",
       "           8.4169e-03, -1.0818e-03, -3.0128e-02, -2.9361e-03, -6.0109e-02,\n",
       "          -7.1948e-02,  5.9290e-02,  6.5829e-02,  2.2809e-02,  8.1467e-02,\n",
       "           2.5373e-02,  9.0451e-02,  3.0150e-02,  3.3593e-02,  2.2198e-02,\n",
       "           3.0221e-02, -7.7347e-02, -4.8809e-02, -9.4529e-02,  7.3213e-02,\n",
       "           1.2963e-02,  1.1992e-01, -5.3982e-02,  2.3161e-02, -4.6373e-02,\n",
       "           1.1438e-01,  4.9741e-02, -6.0138e-02,  6.0772e-03,  1.6590e-02,\n",
       "          -6.5084e-02,  8.7277e-03, -5.8723e-02,  5.5653e-02, -6.0152e-02,\n",
       "          -6.3354e-02,  6.5173e-02, -2.3241e-02, -1.1763e-01,  1.0306e-01,\n",
       "          -1.5366e-02,  2.3074e-02,  4.5913e-02, -9.8835e-02],\n",
       "         [-1.2165e-01, -1.1874e-01, -6.9896e-03,  8.2562e-02,  1.3785e-02,\n",
       "           9.8736e-02, -6.5013e-02,  9.4670e-02, -9.2587e-02,  9.3328e-03,\n",
       "          -7.6171e-02, -7.4658e-02, -1.1917e-01, -4.3517e-02,  7.9249e-02,\n",
       "          -8.3163e-02, -1.1975e-01,  3.7111e-02,  4.8707e-02,  9.1350e-02,\n",
       "           8.0113e-02, -9.4049e-02, -4.0419e-02,  2.4316e-02,  7.9722e-02,\n",
       "           1.0452e-01, -9.2008e-02,  4.6993e-02,  6.9740e-02,  6.0016e-03,\n",
       "           2.1191e-03,  1.7507e-03,  1.0151e-01, -9.8525e-02, -9.7397e-02,\n",
       "          -9.5519e-02,  1.1251e-01, -4.8129e-02, -4.0655e-02,  7.4094e-02,\n",
       "           9.2983e-02,  8.5300e-02,  1.2388e-01, -4.7174e-02,  7.5560e-02,\n",
       "           1.2159e-01, -5.1201e-02, -6.8167e-02,  4.1293e-02, -9.9935e-02,\n",
       "          -9.3915e-02, -7.2033e-03, -2.3866e-02, -1.2015e-02,  1.2196e-01,\n",
       "           1.2796e-02, -1.1590e-02, -3.2201e-02,  9.5205e-03,  3.1762e-02,\n",
       "           1.1809e-01,  1.0478e-01, -9.7057e-02, -6.4577e-02]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0365, -0.0211, -0.0485], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose which parameters we will be updating during training\n",
    "params_to_update = [param for param in pretrained_model.parameters() if param.requires_grad]\n",
    "params_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ebbee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "learning_rate = 1e-5\n",
    "batch_size = 32\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7912b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the loss function and choose an optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=learning_rate)\n",
    "train_dataloader = DataLoader(train_dataset_orig, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset_orig, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c884e153",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "train_loss: 1.0940569639205933\n",
      "Train Accuracy: 37.51%\n",
      "Test Accuracy: 42.65%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "train_loss: 1.0990331172943115\n",
      "Train Accuracy: 38.78%\n",
      "Test Accuracy: 42.71%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "train_loss: 1.0591241121292114\n",
      "Train Accuracy: 38.9%\n",
      "Test Accuracy: 42.37%\n",
      "\n",
      "epoch 4 ==================================================\n",
      "train_loss: 1.1087825298309326\n",
      "Train Accuracy: 39.73%\n",
      "Test Accuracy: 42.25%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, pretrained_model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, pretrained_model, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d3426",
   "metadata": {},
   "source": [
    "### 2-1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b1bf1",
   "metadata": {},
   "source": [
    "As we can see, the accuray is improved, since we are using a pretrained network and it's trained on a huge dataset.It extracts features from images much better than our own network, resulting in better classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33166d96",
   "metadata": {},
   "source": [
    "### 3-1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "587a6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs of the pretrained model\n",
    "train_dataloader = DataLoader(train_dataset_orig, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset_orig, batch_size=1, shuffle=False)\n",
    "pretrained_model_outputs_train = []\n",
    "pretrained_model_outputs_test = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "def test_loop2(dataloader, model, item_list, label_list):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X).flatten()\n",
    "            item_list.append(y_pred)\n",
    "            label_list.append(y.item())\n",
    "\n",
    "test_loop2(train_dataloader, pretrained_model, pretrained_model_outputs_train, train_labels)\n",
    "test_loop2(test_dataloader, pretrained_model, pretrained_model_outputs_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98a2f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outputs of the augmented model\n",
    "train_dataloader = DataLoader(train_dataset_orig, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset_orig, batch_size=1, shuffle=False)\n",
    "augmented_model_outputs_train = []\n",
    "augmented_model_outputs_test = []\n",
    "num_faces_train = []\n",
    "num_faces_test = []\n",
    "\n",
    "def test_loop3(dataloader, model, num_faces_append_list, output_append_list):\n",
    "    model.eval()\n",
    "    to_pil_image = ToPILImage()\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = to_pil_image(X.squeeze())\n",
    "            faces = mtcnn(X)\n",
    "            true_label = torch.tensor(label).to(device)\n",
    "            if faces is None:\n",
    "                # if there is no face in the image, use [0, 0, 0] as output\n",
    "                num_faces_append_list.append(torch.tensor([0]).to(device))\n",
    "                output_append_list.append(torch.tensor([0., 0., 0.]).to(device))\n",
    "                continue\n",
    "            num_faces_append_list.append(torch.tensor([len(faces)]).to(device))\n",
    "            estimated_logits = []\n",
    "            for face in faces:\n",
    "                face = face.permute(1, 2, 0)  \n",
    "                face = torch.tensor(cv2.resize(face.numpy(), (128, 128)))\n",
    "                face = face.to(device) / 255\n",
    "                face = face.permute(2, 1, 0)\n",
    "                face = face.reshape(1, *face.shape)\n",
    "                y_pred = model(face).flatten()\n",
    "                estimated_logits.append(y_pred)\n",
    "                \n",
    "            logits_avg = sum(estimated_logits) / len(estimated_logits)\n",
    "            output_append_list.append(logits_avg)\n",
    "\n",
    "test_loop3(train_dataloader, model2, num_faces_train, augmented_model_outputs_train)\n",
    "test_loop3(test_dataloader, model2, num_faces_test, augmented_model_outputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9988b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, pretrained_outputs, aug_outputs, num_faces, labels, transform=None, target_transform=None):\n",
    "        self.pretrained_outputs = pretrained_outputs\n",
    "        self.aug_outputs = aug_outputs\n",
    "        self.num_faces = num_faces\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.num_faces)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        item = torch.concat((\n",
    "            self.pretrained_outputs[index],\n",
    "            self.aug_outputs[index],\n",
    "            self.num_faces[index]\n",
    "        ))\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            item = self.transform(item)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "            \n",
    "        return item, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0160450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_mixed = MyDataset(\n",
    "    pretrained_model_outputs_train,\n",
    "    augmented_model_outputs_train,\n",
    "    num_faces_train,\n",
    "    train_labels\n",
    ")\n",
    "\n",
    "test_dataset_mixed = MyDataset(\n",
    "    pretrained_model_outputs_test,\n",
    "    augmented_model_outputs_test,\n",
    "    num_faces_test,\n",
    "    test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8dd9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNetwork3(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(7, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mlp_layers(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca661aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = MLPNetwork3().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3791fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "learning_rate = 5e-5\n",
    "batch_size = 64\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88c874bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=learning_rate)\n",
    "train_dataloader = DataLoader(train_dataset_mixed, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset_mixed, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99980cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "train_loss: 1.0801384449005127\n",
      "Train Accuracy: 34.2%\n",
      "Test Accuracy: 25.62%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "train_loss: 1.170766830444336\n",
      "Train Accuracy: 38.39%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "train_loss: 1.102203607559204\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 4 ==================================================\n",
      "train_loss: 1.0815935134887695\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 5 ==================================================\n",
      "train_loss: 1.0798221826553345\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 6 ==================================================\n",
      "train_loss: 1.1017638444900513\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 7 ==================================================\n",
      "train_loss: 1.1116816997528076\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 8 ==================================================\n",
      "train_loss: 1.1044787168502808\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 9 ==================================================\n",
      "train_loss: 1.1283625364303589\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 10 ==================================================\n",
      "train_loss: 1.0690587759017944\n",
      "Train Accuracy: 38.71%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 11 ==================================================\n",
      "train_loss: 1.0542412996292114\n",
      "Train Accuracy: 38.74%\n",
      "Test Accuracy: 42.69%\n",
      "\n",
      "epoch 12 ==================================================\n",
      "train_loss: 1.1131874322891235\n",
      "Train Accuracy: 39.03%\n",
      "Test Accuracy: 42.29%\n",
      "\n",
      "epoch 13 ==================================================\n",
      "train_loss: 1.0595707893371582\n",
      "Train Accuracy: 39.99%\n",
      "Test Accuracy: 42.23%\n",
      "\n",
      "epoch 14 ==================================================\n",
      "train_loss: 1.0429373979568481\n",
      "Train Accuracy: 40.21%\n",
      "Test Accuracy: 42.14%\n",
      "\n",
      "epoch 15 ==================================================\n",
      "train_loss: 1.1640859842300415\n",
      "Train Accuracy: 40.57%\n",
      "Test Accuracy: 42.17%\n",
      "\n",
      "epoch 16 ==================================================\n",
      "train_loss: 1.0639731884002686\n",
      "Train Accuracy: 40.77%\n",
      "Test Accuracy: 41.66%\n",
      "\n",
      "epoch 17 ==================================================\n",
      "train_loss: 1.0961894989013672\n",
      "Train Accuracy: 40.82%\n",
      "Test Accuracy: 42.02%\n",
      "\n",
      "epoch 18 ==================================================\n",
      "train_loss: 1.1407278776168823\n",
      "Train Accuracy: 40.77%\n",
      "Test Accuracy: 41.03%\n",
      "\n",
      "epoch 19 ==================================================\n",
      "train_loss: 1.0506359338760376\n",
      "Train Accuracy: 40.94%\n",
      "Test Accuracy: 41.11%\n",
      "\n",
      "epoch 20 ==================================================\n",
      "train_loss: 1.0726838111877441\n",
      "Train Accuracy: 41.09%\n",
      "Test Accuracy: 41.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model3, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model3, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a8552fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model3, \"./Models/Part3_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
