{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bafc9ca",
   "metadata": {},
   "source": [
    "### Project Phase 3\n",
    "#### Mohammad Amin Rami 98101588\n",
    "#### Milad Heidari 98101469\n",
    "#### Mohammad Reza Safavi 98106701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ff6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyturk.datasets import MSCTD, OpenViDial\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import(\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertModel,\n",
    "    PerceiverModel,\n",
    "    PerceiverImageProcessor,\n",
    "    PerceiverConfig,\n",
    "    PerceiverFeatureExtractor\n",
    ")\n",
    "from transformers.models.perceiver.modeling_perceiver import(\n",
    "    PerceiverClassificationDecoder,\n",
    "    PerceiverImagePreprocessor,\n",
    "    PerceiverTextPreprocessor,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35fd02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device to cuda if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b648b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:opening and reading files...\n",
      "INFO:root:opening and reading files...\n"
     ]
    }
   ],
   "source": [
    "# load train, dev and test datasets\n",
    "\n",
    "train_dataset_orig = MSCTD(\n",
    "    root='data',\n",
    "    mode='train',\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "test_dataset_orig = MSCTD(\n",
    "    root='data',\n",
    "    mode='test',\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad693f",
   "metadata": {},
   "source": [
    "### 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eef015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer for the bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4407a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and text classifier\n",
    "image_classifier = torch.load('resnet50_phase1.pt').to(device)\n",
    "text_classifier = torch.load('bert_phase2.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd939d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the last fully connected layer of the image classifier\n",
    "image_classifier.fc = nn.Sequential(*image_classifier.fc[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf15386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last fully connected layer of the text classifier\n",
    "\n",
    "text_classifier.dropout = nn.Identity()\n",
    "text_classifier.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2206424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.3, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6308f55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Identity()\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f075f7",
   "metadata": {},
   "source": [
    "From the above configuration, out concatenated vector will be of size 64+768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d3c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, data, image_classifier, text_classifier, image_transform):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = image_transform\n",
    "        self.image_classifier = image_classifier\n",
    "        self.text_classifier = text_classifier\n",
    "        self.image_classifier.eval()\n",
    "        self.text_classifier.eval()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, text, label = self.data[index]\n",
    "        \n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform(image)\n",
    "            \n",
    "        text = tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            max_length=100,\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get logits for image\n",
    "            image = image.to(device).reshape(1, *image.shape)\n",
    "            image_logits = self.image_classifier(image).squeeze()\n",
    "\n",
    "            # Get logits for the text\n",
    "            mask = text['attention_mask'].to(device)\n",
    "            input_id = text['input_ids'].squeeze(1).to(device)\n",
    "            outputs = text_classifier.bert(\n",
    "                input_ids=input_id,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            text_logits = outputs[1].squeeze()\n",
    "        \n",
    "        concatenated_logits = torch.concatenate((image_logits, text_logits))\n",
    "        \n",
    "        return concatenated_logits, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b706fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    data=train_dataset_orig,\n",
    "    image_classifier=image_classifier,\n",
    "    text_classifier=text_classifier,\n",
    "    image_transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = CustomDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    data=test_dataset_orig,\n",
    "    image_classifier=image_classifier,\n",
    "    text_classifier=text_classifier,\n",
    "    image_transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76eae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "          \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(832, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79afece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ee9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 8\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "295fa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a43b0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            predicted_labels.extend(y_pred.argmax(dim=1).cpu())\n",
    "            actual_labels.extend(y.cpu())\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b62e60bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "batch: 0, loss: 1.1168079376220703\n",
      "batch: 100, loss: 0.21748235821723938\n",
      "batch: 200, loss: 0.6896350979804993\n",
      "batch: 300, loss: 0.06214183568954468\n",
      "batch: 400, loss: 0.03819464147090912\n",
      "batch: 500, loss: 0.012161371298134327\n",
      "batch: 600, loss: 0.6945672035217285\n",
      "batch: 700, loss: 0.382959246635437\n",
      "batch: 800, loss: 0.08810721337795258\n",
      "batch: 900, loss: 0.1785423755645752\n",
      "batch: 1000, loss: 0.7427043914794922\n",
      "batch: 1100, loss: 0.14959308505058289\n",
      "batch: 1200, loss: 0.06341037154197693\n",
      "batch: 1300, loss: 0.03239846229553223\n",
      "batch: 1400, loss: 0.10969538986682892\n",
      "batch: 1500, loss: 0.17368629574775696\n",
      "batch: 1600, loss: 0.01154499500989914\n",
      "batch: 1700, loss: 0.6333286762237549\n",
      "batch: 1800, loss: 0.1456286460161209\n",
      "batch: 1900, loss: 0.0740758627653122\n",
      "batch: 2000, loss: 0.0842398926615715\n",
      "batch: 2100, loss: 0.04800854250788689\n",
      "batch: 2200, loss: 0.8521721363067627\n",
      "batch: 2300, loss: 0.03954625129699707\n",
      "batch: 2400, loss: 0.02905510738492012\n",
      "batch: 2500, loss: 0.06181458383798599\n",
      "train_loss: 0.5845140218734741\n",
      "Train Accuracy: 92.49%\n",
      "Test Accuracy: 58.73%\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "775b574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'resnet_bert.pt')\n",
    "model = torch.load('resnet_bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb218183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.61      0.51      1298\n",
      "           1       0.72      0.61      0.66      2163\n",
      "           2       0.61      0.53      0.57      1606\n",
      "\n",
      "    accuracy                           0.59      5067\n",
      "   macro avg       0.59      0.59      0.58      5067\n",
      "weighted avg       0.61      0.59      0.59      5067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b50c8d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "label_maps = ['neutral', 'negative', 'positive']\n",
    "confmat = confusion_matrix(actual_labels, predicted_labels)\n",
    "sns.heatmap(\n",
    "    confmat,\n",
    "    xticklabels=label_maps,\n",
    "    yticklabels=label_maps,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='BuGn'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39737bc1",
   "metadata": {},
   "source": [
    "### 1-2 (Clip + MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a107cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdcfcf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "clip = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "clip.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023850f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset2(Dataset):\n",
    "    \n",
    "    def __init__(self, embed_model, data, processor):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.embed_model = embed_model\n",
    "        self.embed_model.eval()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image, text, label = self.data[index]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            inputs = self.processor(\n",
    "                text=text,\n",
    "                images=image,\n",
    "                return_tensors='pt',\n",
    "                padding=True\n",
    "            )\n",
    "            output = self.embed_model(**inputs.to(device))\n",
    "            text_embeds = output.text_embeds.flatten()\n",
    "            image_embeds = output.image_embeds.flatten()\n",
    "            \n",
    "        concat_embeds = torch.concatenate((text_embeds, image_embeds))\n",
    "        \n",
    "        return concat_embeds, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98c7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "\n",
    "train_data = CustomDataset2(\n",
    "    data=train_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")\n",
    "\n",
    "test_data = CustomDataset2(\n",
    "    data=test_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b105e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextImageClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e268544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextImageClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffac523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 4\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aedcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257fc0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            predicted_labels.extend(y_pred.argmax(dim=1).cpu())\n",
    "            actual_labels.extend(y.cpu())\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7128c820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "batch: 0, loss: 1.1110637187957764\n",
      "batch: 100, loss: 0.9956274628639221\n",
      "batch: 200, loss: 1.1902170181274414\n",
      "batch: 300, loss: 1.1032330989837646\n",
      "batch: 400, loss: 1.0131819248199463\n",
      "batch: 500, loss: 1.00348699092865\n",
      "batch: 600, loss: 1.0735417604446411\n",
      "batch: 700, loss: 1.2321919202804565\n",
      "batch: 800, loss: 1.093709945678711\n",
      "batch: 900, loss: 1.0208579301834106\n",
      "batch: 1000, loss: 1.0006641149520874\n",
      "batch: 1100, loss: 1.0060185194015503\n",
      "batch: 1200, loss: 1.1156706809997559\n",
      "batch: 1300, loss: 1.04714035987854\n",
      "batch: 1400, loss: 1.0314202308654785\n",
      "batch: 1500, loss: 1.0677456855773926\n",
      "batch: 1600, loss: 1.0429465770721436\n",
      "batch: 1700, loss: 1.0276182889938354\n",
      "batch: 1800, loss: 1.0554625988006592\n",
      "batch: 1900, loss: 1.051159381866455\n",
      "batch: 2000, loss: 0.9282623529434204\n",
      "batch: 2100, loss: 1.1629449129104614\n",
      "batch: 2200, loss: 1.1057913303375244\n",
      "batch: 2300, loss: 0.9543439745903015\n",
      "batch: 2400, loss: 1.101118564605713\n",
      "batch: 2500, loss: 1.341139793395996\n",
      "batch: 2600, loss: 0.9384171366691589\n",
      "batch: 2700, loss: 1.0317326784133911\n",
      "batch: 2800, loss: 1.0913679599761963\n",
      "batch: 2900, loss: 0.6645478010177612\n",
      "batch: 3000, loss: 0.6756218075752258\n",
      "batch: 3100, loss: 1.277071475982666\n",
      "batch: 3200, loss: 0.8109073638916016\n",
      "batch: 3300, loss: 1.2758138179779053\n",
      "batch: 3400, loss: 0.9277516007423401\n",
      "batch: 3500, loss: 0.7122290134429932\n",
      "batch: 3600, loss: 1.1176356077194214\n",
      "batch: 3700, loss: 1.1023175716400146\n",
      "batch: 3800, loss: 0.7501190304756165\n",
      "batch: 3900, loss: 1.0912494659423828\n",
      "batch: 4000, loss: 0.9251422882080078\n",
      "batch: 4100, loss: 0.899836540222168\n",
      "batch: 4200, loss: 0.9363410472869873\n",
      "batch: 4300, loss: 0.9875463247299194\n",
      "batch: 4400, loss: 1.0938102006912231\n",
      "batch: 4500, loss: 0.8317943811416626\n",
      "batch: 4600, loss: 1.1712353229522705\n",
      "batch: 4700, loss: 0.9386830925941467\n",
      "batch: 4800, loss: 0.9789847731590271\n",
      "batch: 4900, loss: 0.5753834247589111\n",
      "batch: 5000, loss: 0.8392282724380493\n",
      "train_loss: 1.0678247213363647\n",
      "Train Accuracy: 48.13%\n",
      "Test Accuracy: 52.83%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "batch: 0, loss: 1.0339593887329102\n",
      "batch: 100, loss: 1.243323564529419\n",
      "batch: 200, loss: 0.8657152056694031\n",
      "batch: 300, loss: 1.1457197666168213\n",
      "batch: 400, loss: 0.8352236747741699\n",
      "batch: 500, loss: 0.9457728862762451\n",
      "batch: 600, loss: 0.8841167092323303\n",
      "batch: 700, loss: 1.129617691040039\n",
      "batch: 800, loss: 0.9568618535995483\n",
      "batch: 900, loss: 0.7263416647911072\n",
      "batch: 1000, loss: 0.555538535118103\n",
      "batch: 1100, loss: 1.0287954807281494\n",
      "batch: 1200, loss: 0.7232874035835266\n",
      "batch: 1300, loss: 1.191214919090271\n",
      "batch: 1400, loss: 1.2894158363342285\n",
      "batch: 1500, loss: 0.6083096861839294\n",
      "batch: 1600, loss: 1.1470942497253418\n",
      "batch: 1700, loss: 1.2958358526229858\n",
      "batch: 1800, loss: 0.8167142868041992\n",
      "batch: 1900, loss: 1.245476484298706\n",
      "batch: 2000, loss: 1.0565241575241089\n",
      "batch: 2100, loss: 1.0473421812057495\n",
      "batch: 2200, loss: 1.2379834651947021\n",
      "batch: 2300, loss: 0.6885931491851807\n",
      "batch: 2400, loss: 0.6485193967819214\n",
      "batch: 2500, loss: 1.1831037998199463\n",
      "batch: 2600, loss: 1.1326932907104492\n",
      "batch: 2700, loss: 1.2346218824386597\n",
      "batch: 2800, loss: 1.1845557689666748\n",
      "batch: 2900, loss: 0.5888549089431763\n",
      "batch: 3000, loss: 1.061535120010376\n",
      "batch: 3100, loss: 1.2239265441894531\n",
      "batch: 3200, loss: 0.567815899848938\n",
      "batch: 3300, loss: 0.8942509889602661\n",
      "batch: 3400, loss: 0.8031024932861328\n",
      "batch: 3500, loss: 1.237428903579712\n",
      "batch: 3600, loss: 1.0078036785125732\n",
      "batch: 3700, loss: 0.5407997965812683\n",
      "batch: 3800, loss: 0.9389075040817261\n",
      "batch: 3900, loss: 0.5664047002792358\n",
      "batch: 4000, loss: 1.0143400430679321\n",
      "batch: 4100, loss: 1.0992538928985596\n",
      "batch: 4200, loss: 0.7175079584121704\n",
      "batch: 4300, loss: 1.265271782875061\n",
      "batch: 4400, loss: 0.4741027057170868\n",
      "batch: 4500, loss: 1.290069818496704\n",
      "batch: 4600, loss: 0.8228985071182251\n",
      "batch: 4700, loss: 1.213472604751587\n",
      "batch: 4800, loss: 1.4532052278518677\n",
      "batch: 4900, loss: 0.8231335878372192\n",
      "batch: 5000, loss: 0.8272329568862915\n",
      "train_loss: 0.747864305973053\n",
      "Train Accuracy: 58.11%\n",
      "Test Accuracy: 58.69%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "batch: 0, loss: 0.5091763734817505\n",
      "batch: 100, loss: 1.0662801265716553\n",
      "batch: 200, loss: 0.40130946040153503\n",
      "batch: 300, loss: 0.5808400511741638\n",
      "batch: 400, loss: 0.6280419230461121\n",
      "batch: 500, loss: 0.8293907642364502\n",
      "batch: 600, loss: 0.9524688720703125\n",
      "batch: 700, loss: 1.4913069009780884\n",
      "batch: 800, loss: 0.5897809267044067\n",
      "batch: 900, loss: 1.282384991645813\n",
      "batch: 1000, loss: 1.1631866693496704\n",
      "batch: 1100, loss: 0.8903443217277527\n",
      "batch: 1200, loss: 1.4033452272415161\n",
      "batch: 1300, loss: 1.4256715774536133\n",
      "batch: 1400, loss: 0.8383592367172241\n",
      "batch: 1500, loss: 0.7758926749229431\n",
      "batch: 1600, loss: 0.9061694741249084\n",
      "batch: 1700, loss: 1.4822871685028076\n",
      "batch: 1800, loss: 0.7045347690582275\n",
      "batch: 1900, loss: 0.6763896346092224\n",
      "batch: 2000, loss: 0.751266598701477\n",
      "batch: 2100, loss: 0.6989781260490417\n",
      "batch: 2200, loss: 0.5933015942573547\n",
      "batch: 2300, loss: 0.5696010589599609\n",
      "batch: 2400, loss: 0.7023036479949951\n",
      "batch: 2500, loss: 0.8953949213027954\n",
      "batch: 2600, loss: 1.3415123224258423\n",
      "batch: 2700, loss: 0.5017699003219604\n",
      "batch: 2800, loss: 1.0134526491165161\n",
      "batch: 2900, loss: 0.8731594681739807\n",
      "batch: 3000, loss: 1.0845201015472412\n",
      "batch: 3100, loss: 1.1260192394256592\n",
      "batch: 3200, loss: 1.1383171081542969\n",
      "batch: 3300, loss: 0.7873451709747314\n",
      "batch: 3400, loss: 0.6752835512161255\n",
      "batch: 3500, loss: 1.101912021636963\n",
      "batch: 3600, loss: 0.897704005241394\n",
      "batch: 3700, loss: 0.9942129850387573\n",
      "batch: 3800, loss: 1.524472951889038\n",
      "batch: 3900, loss: 0.7111269235610962\n",
      "batch: 4000, loss: 1.4102156162261963\n",
      "batch: 4100, loss: 1.1808457374572754\n",
      "batch: 4200, loss: 0.714664101600647\n",
      "batch: 4300, loss: 0.584931492805481\n",
      "batch: 4400, loss: 1.1241631507873535\n",
      "batch: 4500, loss: 1.0171101093292236\n",
      "batch: 4600, loss: 0.9479323029518127\n",
      "batch: 4700, loss: 0.7079033851623535\n",
      "batch: 4800, loss: 0.8292334675788879\n",
      "batch: 4900, loss: 0.7106766700744629\n",
      "batch: 5000, loss: 0.9124407172203064\n",
      "train_loss: 0.610776424407959\n",
      "Train Accuracy: 60.22%\n",
      "Test Accuracy: 57.25%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9db1974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'clip_mlp.pt')\n",
    "model = torch.load('clip_mlp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f1cbbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46      3894\n",
      "           1       0.62      0.74      0.67      6489\n",
      "           2       0.62      0.38      0.47      4818\n",
      "\n",
      "    accuracy                           0.56     15201\n",
      "   macro avg       0.56      0.54      0.54     15201\n",
      "weighted avg       0.57      0.56      0.55     15201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e08696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "label_maps = ['neutral', 'negative', 'positive']\n",
    "confmat = confusion_matrix(actual_labels, predicted_labels)\n",
    "sns.heatmap(\n",
    "    confmat,\n",
    "    xticklabels=label_maps,\n",
    "    yticklabels=label_maps,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Purples'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856c484",
   "metadata": {},
   "source": [
    "### 1-2 (Perceiver Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb224c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfb948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "clip = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "clip.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cace3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset3(Dataset):\n",
    "    \n",
    "    def __init__(self, embed_model, data, processor):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.embed_model = embed_model\n",
    "        self.embed_model.eval()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image, text, label = self.data[index]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            inputs = self.processor(\n",
    "                text=text,\n",
    "                images=image,\n",
    "                return_tensors='pt',\n",
    "                padding=True\n",
    "            )\n",
    "            output = self.embed_model(**inputs.to(device))\n",
    "            text_embeds = output.text_embeds\n",
    "            image_embeds = output.image_embeds\n",
    "            \n",
    "        concat_embeds = torch.concatenate((text_embeds, image_embeds), dim=1)\n",
    "        \n",
    "        return concat_embeds, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ca989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "\n",
    "train_data = CustomDataset3(\n",
    "    data=train_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")\n",
    "\n",
    "test_data = CustomDataset3(\n",
    "    data=test_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5f5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config of the model\n",
    "\n",
    "config = PerceiverConfig()\n",
    "config.num_labels = 3\n",
    "config.d_model = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512fab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceiverClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.perceiver = PerceiverModel(\n",
    "            config=config,\n",
    "            decoder=PerceiverClassificationDecoder(\n",
    "                config,\n",
    "                num_channels=config.d_latents,\n",
    "                trainable_position_encoding_kwargs=dict(num_channels=config.d_latents, index_dims=1),\n",
    "                use_query_residual=True,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.identity = nn.Identity()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.perceiver(x).logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc63215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a perceiver model\n",
    "perceiver_classifier = PerceiverClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3414fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 3e-5\n",
    "batch_size = 1\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef0e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(perceiver_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fcd5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc282d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.81 GiB total capacity; 2.53 GiB already allocated; 16.44 MiB free; 2.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperceiver_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     test_loop(test_dataloader, perceiver_classifier, loss_fn)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# back prop\u001b[39;00m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.81 GiB total capacity; 2.53 GiB already allocated; 16.44 MiB free; 2.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, perceiver_classifier, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, perceiver_classifier, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4ec6c",
   "metadata": {},
   "source": [
    "### 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019601c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer for the bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1520da",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resnet50_phase1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load image and text classifier\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet50_phase1.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m text_classifier \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_phase2.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resnet50_phase1.pt'"
     ]
    }
   ],
   "source": [
    "# Load image and text classifier\n",
    "image_classifier = torch.load('resnet50_phase1.pt').to(device)\n",
    "text_classifier = torch.load('bert_phase2.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f07ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OpenViDial(\n",
    "    data_path=pathlib.Path('./data/OpenViDial'),\n",
    "    image_transform=Compose([\n",
    "        Resize((64, 128)),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    text_transform=lambda x: tokenizer(\n",
    "        x,\n",
    "        padding='max_length',\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad17e6c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ba2c1f163240af8950700976d79ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting pseudo labels using text_classifier model\n",
    "batch_size = 16\n",
    "pseudo_labels = []\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "text_classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text, _ in tqdm(dataloader):\n",
    "        # Get logits for the text\n",
    "        mask = text['attention_mask'].to(device)\n",
    "        input_id = text['input_ids'].squeeze(1).to(device)\n",
    "        outputs = text_classifier(\n",
    "            input_ids=input_id,\n",
    "            attention_mask=mask,\n",
    "        )\n",
    "        \n",
    "        text_logits = outputs.logits\n",
    "        pseudo_labels.extend(nn.functional.softmax(text_logits, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ee308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom dataset for vision model learning\n",
    "\n",
    "class VisionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _, image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea67aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for vision dataset\n",
    "\n",
    "vision_dataset = VisionDataset(\n",
    "    data=dataset,\n",
    "    labels=pseudo_labels\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(vision_dataset))\n",
    "test_size = len(vision_dataset) - train_size\n",
    "train_set, test_set = random_split(vision_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ae6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the vision model using pseudo labels from the text model\n",
    "\n",
    "# define hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a43b25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(image_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e10c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y.argmax(dim=1)).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            predicted_labels.extend(y_pred.argmax(dim=1).cpu())\n",
    "            actual_labels.extend(y.argmax(dim=1).cpu())\n",
    "            num_correct += (y_pred.argmax(dim=1) == y.argmax(dim=1)).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bff87761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "batch: 0, loss: 0.2204660028219223\n",
      "batch: 100, loss: 0.13178375363349915\n",
      "batch: 200, loss: 0.12107579410076141\n",
      "batch: 300, loss: 0.1280219554901123\n",
      "batch: 400, loss: 0.1024543046951294\n",
      "batch: 500, loss: 0.129855677485466\n",
      "batch: 600, loss: 0.13010871410369873\n",
      "batch: 700, loss: 0.10621442645788193\n",
      "batch: 800, loss: 0.12876452505588531\n",
      "batch: 900, loss: 0.10075634717941284\n",
      "batch: 1000, loss: 0.11245086044073105\n",
      "batch: 1100, loss: 0.12154191732406616\n",
      "batch: 1200, loss: 0.10519742220640182\n",
      "batch: 1300, loss: 0.0843239426612854\n",
      "batch: 1400, loss: 0.131372332572937\n",
      "batch: 1500, loss: 0.12041952461004257\n",
      "batch: 1600, loss: 0.14739519357681274\n",
      "batch: 1700, loss: 0.10339528322219849\n",
      "batch: 1800, loss: 0.14102047681808472\n",
      "batch: 1900, loss: 0.0972752496600151\n",
      "batch: 2000, loss: 0.13379532098770142\n",
      "batch: 2100, loss: 0.11595332622528076\n",
      "batch: 2200, loss: 0.10784631967544556\n",
      "batch: 2300, loss: 0.12544070184230804\n",
      "batch: 2400, loss: 0.10637781023979187\n",
      "batch: 2500, loss: 0.10610940307378769\n",
      "batch: 2600, loss: 0.14688798785209656\n",
      "batch: 2700, loss: 0.1178334504365921\n",
      "train_loss: 0.1280149668455124\n",
      "Train Accuracy: 43.61%\n",
      "Test Accuracy: 43.61%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "batch: 0, loss: 0.10527485609054565\n",
      "batch: 100, loss: 0.1315452754497528\n",
      "batch: 200, loss: 0.11701849102973938\n",
      "batch: 300, loss: 0.1229303702712059\n",
      "batch: 400, loss: 0.08271974325180054\n",
      "batch: 500, loss: 0.11368493735790253\n",
      "batch: 600, loss: 0.11018574237823486\n",
      "batch: 700, loss: 0.13207654654979706\n",
      "batch: 800, loss: 0.10772838443517685\n",
      "batch: 900, loss: 0.1207636296749115\n",
      "batch: 1000, loss: 0.09286221116781235\n",
      "batch: 1100, loss: 0.14791126549243927\n",
      "batch: 1200, loss: 0.11020328849554062\n",
      "batch: 1300, loss: 0.09365737438201904\n",
      "batch: 1400, loss: 0.10273372381925583\n",
      "batch: 1500, loss: 0.08178973197937012\n",
      "batch: 1600, loss: 0.10277323424816132\n",
      "batch: 1700, loss: 0.10035461187362671\n",
      "batch: 1800, loss: 0.10816378891468048\n",
      "batch: 1900, loss: 0.09167065471410751\n",
      "batch: 2000, loss: 0.103338822722435\n",
      "batch: 2100, loss: 0.10399957746267319\n",
      "batch: 2200, loss: 0.12067747116088867\n",
      "batch: 2300, loss: 0.11038221418857574\n",
      "batch: 2400, loss: 0.09562727808952332\n",
      "batch: 2500, loss: 0.11863579601049423\n",
      "batch: 2600, loss: 0.11406254768371582\n",
      "batch: 2700, loss: 0.10602875053882599\n",
      "train_loss: 0.10588014125823975\n",
      "Train Accuracy: 43.91%\n",
      "Test Accuracy: 43.79%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "batch: 0, loss: 0.11462976783514023\n",
      "batch: 100, loss: 0.09824232757091522\n",
      "batch: 200, loss: 0.1200162023305893\n",
      "batch: 300, loss: 0.10422184318304062\n",
      "batch: 400, loss: 0.1156356930732727\n",
      "batch: 500, loss: 0.11609159409999847\n",
      "batch: 600, loss: 0.13230763375759125\n",
      "batch: 700, loss: 0.11820446699857712\n",
      "batch: 800, loss: 0.13831616938114166\n",
      "batch: 900, loss: 0.12414178252220154\n",
      "batch: 1000, loss: 0.12468105554580688\n",
      "batch: 1100, loss: 0.12068399041891098\n",
      "batch: 1200, loss: 0.09784440696239471\n",
      "batch: 1300, loss: 0.10980477184057236\n",
      "batch: 1400, loss: 0.12654823064804077\n",
      "batch: 1500, loss: 0.09624958038330078\n",
      "batch: 1600, loss: 0.0860845297574997\n",
      "batch: 1700, loss: 0.08516343683004379\n",
      "batch: 1800, loss: 0.09899663925170898\n",
      "batch: 1900, loss: 0.10157084465026855\n",
      "batch: 2000, loss: 0.12403538078069687\n",
      "batch: 2100, loss: 0.11508592218160629\n",
      "batch: 2200, loss: 0.1390068233013153\n",
      "batch: 2300, loss: 0.09272664040327072\n",
      "batch: 2400, loss: 0.11632376909255981\n",
      "batch: 2500, loss: 0.0911196917295456\n",
      "batch: 2600, loss: 0.11846105754375458\n",
      "batch: 2700, loss: 0.11437034606933594\n",
      "train_loss: 0.10951642692089081\n",
      "Train Accuracy: 43.98%\n",
      "Test Accuracy: 43.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, image_classifier, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, image_classifier, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ab3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(image_classifier, 'domain_adaptation.pt')\n",
    "image_classifier = torch.load('domain_adaptation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a17cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.03      0.05     11142\n",
      "           1       0.44      0.98      0.61     14610\n",
      "           2       0.00      0.00      0.00      7650\n",
      "\n",
      "    accuracy                           0.44     33402\n",
      "   macro avg       0.28      0.34      0.22     33402\n",
      "weighted avg       0.33      0.44      0.28     33402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33dc9d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "label_maps = ['neutral', 'negative', 'positive']\n",
    "confmat = confusion_matrix(actual_labels, predicted_labels)\n",
    "sns.heatmap(\n",
    "    confmat,\n",
    "    xticklabels=label_maps,\n",
    "    yticklabels=label_maps,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues'\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
