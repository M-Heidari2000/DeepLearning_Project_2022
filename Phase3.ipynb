{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bafc9ca",
   "metadata": {},
   "source": [
    "### Project Phase 3\n",
    "#### Mohammad Amin Rami 98101588\n",
    "#### Milad Heidari 98101469\n",
    "#### Mohammad Reza Safavi 98106701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ff6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pyturk.datasets import MSCTD, OpenViDial\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import(\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertModel,\n",
    "    PerceiverModel,\n",
    "    PerceiverImageProcessor,\n",
    "    PerceiverConfig,\n",
    "    PerceiverFeatureExtractor\n",
    ")\n",
    "from transformers.models.perceiver.modeling_perceiver import(\n",
    "    PerceiverClassificationDecoder,\n",
    "    PerceiverImagePreprocessor,\n",
    "    PerceiverTextPreprocessor,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35fd02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device to cuda if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b648b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:opening and reading files...\n",
      "INFO:root:opening and reading files...\n"
     ]
    }
   ],
   "source": [
    "# load train, dev and test datasets\n",
    "\n",
    "train_dataset_orig = MSCTD(\n",
    "    root='data',\n",
    "    mode='train',\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "test_dataset_orig = MSCTD(\n",
    "    root='data',\n",
    "    mode='test',\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad693f",
   "metadata": {},
   "source": [
    "### 1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eef015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer for the bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4407a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and text classifier\n",
    "image_classifier = torch.load('resnet50_phase1.pt').to(device)\n",
    "text_classifier = torch.load('bert_phase2.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd939d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the last fully connected layer of the image classifier\n",
    "image_classifier.fc = nn.Sequential(*image_classifier.fc[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf15386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last fully connected layer of the text classifier\n",
    "\n",
    "text_classifier.dropout = nn.Identity()\n",
    "text_classifier.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2206424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): Dropout(p=0.3, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6308f55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Identity()\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f075f7",
   "metadata": {},
   "source": [
    "From the above configuration, out concatenated vector will be of size 64+768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d3c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, data, image_classifier, text_classifier, image_transform):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.image_transform = image_transform\n",
    "        self.image_classifier = image_classifier\n",
    "        self.text_classifier = text_classifier\n",
    "        self.image_classifier.eval()\n",
    "        self.text_classifier.eval()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image, text, label = self.data[index]\n",
    "        \n",
    "        if self.image_transform is not None:\n",
    "            image = self.image_transform(image)\n",
    "            \n",
    "        text = tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            max_length=100,\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Get logits for image\n",
    "            image = image.to(device).reshape(1, *image.shape)\n",
    "            image_logits = self.image_classifier(image).squeeze()\n",
    "\n",
    "            # Get logits for the text\n",
    "            mask = text['attention_mask'].to(device)\n",
    "            input_id = text['input_ids'].squeeze(1).to(device)\n",
    "            outputs = text_classifier.bert(\n",
    "                input_ids=input_id,\n",
    "                attention_mask=mask,\n",
    "            )\n",
    "            text_logits = outputs[1].squeeze()\n",
    "        \n",
    "        concatenated_logits = torch.concatenate((image_logits, text_logits))\n",
    "        \n",
    "        return concatenated_logits, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b706fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    data=train_dataset_orig,\n",
    "    image_classifier=image_classifier,\n",
    "    text_classifier=text_classifier,\n",
    "    image_transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = CustomDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    data=test_dataset_orig,\n",
    "    image_classifier=image_classifier,\n",
    "    text_classifier=text_classifier,\n",
    "    image_transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d76eae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "          \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(832, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79afece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ee9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 8\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "295fa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a43b0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            predicted_labels.extend(y_pred.argmax(dim=1).cpu())\n",
    "            actual_labels.extend(y.cpu())\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b62e60bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "batch: 0, loss: 1.1168079376220703\n",
      "batch: 100, loss: 0.21748235821723938\n",
      "batch: 200, loss: 0.6896350979804993\n",
      "batch: 300, loss: 0.06214183568954468\n",
      "batch: 400, loss: 0.03819464147090912\n",
      "batch: 500, loss: 0.012161371298134327\n",
      "batch: 600, loss: 0.6945672035217285\n",
      "batch: 700, loss: 0.382959246635437\n",
      "batch: 800, loss: 0.08810721337795258\n",
      "batch: 900, loss: 0.1785423755645752\n",
      "batch: 1000, loss: 0.7427043914794922\n",
      "batch: 1100, loss: 0.14959308505058289\n",
      "batch: 1200, loss: 0.06341037154197693\n",
      "batch: 1300, loss: 0.03239846229553223\n",
      "batch: 1400, loss: 0.10969538986682892\n",
      "batch: 1500, loss: 0.17368629574775696\n",
      "batch: 1600, loss: 0.01154499500989914\n",
      "batch: 1700, loss: 0.6333286762237549\n",
      "batch: 1800, loss: 0.1456286460161209\n",
      "batch: 1900, loss: 0.0740758627653122\n",
      "batch: 2000, loss: 0.0842398926615715\n",
      "batch: 2100, loss: 0.04800854250788689\n",
      "batch: 2200, loss: 0.8521721363067627\n",
      "batch: 2300, loss: 0.03954625129699707\n",
      "batch: 2400, loss: 0.02905510738492012\n",
      "batch: 2500, loss: 0.06181458383798599\n",
      "train_loss: 0.5845140218734741\n",
      "Train Accuracy: 92.49%\n",
      "Test Accuracy: 58.73%\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "775b574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'resnet_bert.pt')\n",
    "model = torch.load('resnet_bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb218183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.61      0.51      1298\n",
      "           1       0.72      0.61      0.66      2163\n",
      "           2       0.61      0.53      0.57      1606\n",
      "\n",
      "    accuracy                           0.59      5067\n",
      "   macro avg       0.59      0.59      0.58      5067\n",
      "weighted avg       0.61      0.59      0.59      5067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b50c8d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "label_maps = ['neutral', 'negative', 'positive']\n",
    "confmat = confusion_matrix(actual_labels, predicted_labels)\n",
    "sns.heatmap(\n",
    "    confmat,\n",
    "    xticklabels=label_maps,\n",
    "    yticklabels=label_maps,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='BuGn'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39737bc1",
   "metadata": {},
   "source": [
    "### 1-2 (Clip + MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a107cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdcfcf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "clip = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "clip.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023850f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset2(Dataset):\n",
    "    \n",
    "    def __init__(self, embed_model, data, processor):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.embed_model = embed_model\n",
    "        self.embed_model.eval()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image, text, label = self.data[index]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            inputs = self.processor(\n",
    "                text=text,\n",
    "                images=image,\n",
    "                return_tensors='pt',\n",
    "                padding=True\n",
    "            )\n",
    "            output = self.embed_model(**inputs.to(device))\n",
    "            text_embeds = output.text_embeds.flatten()\n",
    "            image_embeds = output.image_embeds.flatten()\n",
    "            \n",
    "        concat_embeds = torch.concatenate((text_embeds, image_embeds))\n",
    "        \n",
    "        return concat_embeds, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98c7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "\n",
    "train_data = CustomDataset2(\n",
    "    data=train_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")\n",
    "\n",
    "test_data = CustomDataset2(\n",
    "    data=test_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b105e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextImageClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 3)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e268544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextImageClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffac523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 1e-4\n",
    "batch_size = 4\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aedcf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257fc0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            predicted_labels.extend(y_pred.argmax(dim=1).cpu())\n",
    "            actual_labels.extend(y.cpu())\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7128c820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "batch: 0, loss: 1.1110637187957764\n",
      "batch: 100, loss: 0.9956274628639221\n",
      "batch: 200, loss: 1.1902170181274414\n",
      "batch: 300, loss: 1.1032330989837646\n",
      "batch: 400, loss: 1.0131819248199463\n",
      "batch: 500, loss: 1.00348699092865\n",
      "batch: 600, loss: 1.0735417604446411\n",
      "batch: 700, loss: 1.2321919202804565\n",
      "batch: 800, loss: 1.093709945678711\n",
      "batch: 900, loss: 1.0208579301834106\n",
      "batch: 1000, loss: 1.0006641149520874\n",
      "batch: 1100, loss: 1.0060185194015503\n",
      "batch: 1200, loss: 1.1156706809997559\n",
      "batch: 1300, loss: 1.04714035987854\n",
      "batch: 1400, loss: 1.0314202308654785\n",
      "batch: 1500, loss: 1.0677456855773926\n",
      "batch: 1600, loss: 1.0429465770721436\n",
      "batch: 1700, loss: 1.0276182889938354\n",
      "batch: 1800, loss: 1.0554625988006592\n",
      "batch: 1900, loss: 1.051159381866455\n",
      "batch: 2000, loss: 0.9282623529434204\n",
      "batch: 2100, loss: 1.1629449129104614\n",
      "batch: 2200, loss: 1.1057913303375244\n",
      "batch: 2300, loss: 0.9543439745903015\n",
      "batch: 2400, loss: 1.101118564605713\n",
      "batch: 2500, loss: 1.341139793395996\n",
      "batch: 2600, loss: 0.9384171366691589\n",
      "batch: 2700, loss: 1.0317326784133911\n",
      "batch: 2800, loss: 1.0913679599761963\n",
      "batch: 2900, loss: 0.6645478010177612\n",
      "batch: 3000, loss: 0.6756218075752258\n",
      "batch: 3100, loss: 1.277071475982666\n",
      "batch: 3200, loss: 0.8109073638916016\n",
      "batch: 3300, loss: 1.2758138179779053\n",
      "batch: 3400, loss: 0.9277516007423401\n",
      "batch: 3500, loss: 0.7122290134429932\n",
      "batch: 3600, loss: 1.1176356077194214\n",
      "batch: 3700, loss: 1.1023175716400146\n",
      "batch: 3800, loss: 0.7501190304756165\n",
      "batch: 3900, loss: 1.0912494659423828\n",
      "batch: 4000, loss: 0.9251422882080078\n",
      "batch: 4100, loss: 0.899836540222168\n",
      "batch: 4200, loss: 0.9363410472869873\n",
      "batch: 4300, loss: 0.9875463247299194\n",
      "batch: 4400, loss: 1.0938102006912231\n",
      "batch: 4500, loss: 0.8317943811416626\n",
      "batch: 4600, loss: 1.1712353229522705\n",
      "batch: 4700, loss: 0.9386830925941467\n",
      "batch: 4800, loss: 0.9789847731590271\n",
      "batch: 4900, loss: 0.5753834247589111\n",
      "batch: 5000, loss: 0.8392282724380493\n",
      "train_loss: 1.0678247213363647\n",
      "Train Accuracy: 48.13%\n",
      "Test Accuracy: 52.83%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "batch: 0, loss: 1.0339593887329102\n",
      "batch: 100, loss: 1.243323564529419\n",
      "batch: 200, loss: 0.8657152056694031\n",
      "batch: 300, loss: 1.1457197666168213\n",
      "batch: 400, loss: 0.8352236747741699\n",
      "batch: 500, loss: 0.9457728862762451\n",
      "batch: 600, loss: 0.8841167092323303\n",
      "batch: 700, loss: 1.129617691040039\n",
      "batch: 800, loss: 0.9568618535995483\n",
      "batch: 900, loss: 0.7263416647911072\n",
      "batch: 1000, loss: 0.555538535118103\n",
      "batch: 1100, loss: 1.0287954807281494\n",
      "batch: 1200, loss: 0.7232874035835266\n",
      "batch: 1300, loss: 1.191214919090271\n",
      "batch: 1400, loss: 1.2894158363342285\n",
      "batch: 1500, loss: 0.6083096861839294\n",
      "batch: 1600, loss: 1.1470942497253418\n",
      "batch: 1700, loss: 1.2958358526229858\n",
      "batch: 1800, loss: 0.8167142868041992\n",
      "batch: 1900, loss: 1.245476484298706\n",
      "batch: 2000, loss: 1.0565241575241089\n",
      "batch: 2100, loss: 1.0473421812057495\n",
      "batch: 2200, loss: 1.2379834651947021\n",
      "batch: 2300, loss: 0.6885931491851807\n",
      "batch: 2400, loss: 0.6485193967819214\n",
      "batch: 2500, loss: 1.1831037998199463\n",
      "batch: 2600, loss: 1.1326932907104492\n",
      "batch: 2700, loss: 1.2346218824386597\n",
      "batch: 2800, loss: 1.1845557689666748\n",
      "batch: 2900, loss: 0.5888549089431763\n",
      "batch: 3000, loss: 1.061535120010376\n",
      "batch: 3100, loss: 1.2239265441894531\n",
      "batch: 3200, loss: 0.567815899848938\n",
      "batch: 3300, loss: 0.8942509889602661\n",
      "batch: 3400, loss: 0.8031024932861328\n",
      "batch: 3500, loss: 1.237428903579712\n",
      "batch: 3600, loss: 1.0078036785125732\n",
      "batch: 3700, loss: 0.5407997965812683\n",
      "batch: 3800, loss: 0.9389075040817261\n",
      "batch: 3900, loss: 0.5664047002792358\n",
      "batch: 4000, loss: 1.0143400430679321\n",
      "batch: 4100, loss: 1.0992538928985596\n",
      "batch: 4200, loss: 0.7175079584121704\n",
      "batch: 4300, loss: 1.265271782875061\n",
      "batch: 4400, loss: 0.4741027057170868\n",
      "batch: 4500, loss: 1.290069818496704\n",
      "batch: 4600, loss: 0.8228985071182251\n",
      "batch: 4700, loss: 1.213472604751587\n",
      "batch: 4800, loss: 1.4532052278518677\n",
      "batch: 4900, loss: 0.8231335878372192\n",
      "batch: 5000, loss: 0.8272329568862915\n",
      "train_loss: 0.747864305973053\n",
      "Train Accuracy: 58.11%\n",
      "Test Accuracy: 58.69%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "batch: 0, loss: 0.5091763734817505\n",
      "batch: 100, loss: 1.0662801265716553\n",
      "batch: 200, loss: 0.40130946040153503\n",
      "batch: 300, loss: 0.5808400511741638\n",
      "batch: 400, loss: 0.6280419230461121\n",
      "batch: 500, loss: 0.8293907642364502\n",
      "batch: 600, loss: 0.9524688720703125\n",
      "batch: 700, loss: 1.4913069009780884\n",
      "batch: 800, loss: 0.5897809267044067\n",
      "batch: 900, loss: 1.282384991645813\n",
      "batch: 1000, loss: 1.1631866693496704\n",
      "batch: 1100, loss: 0.8903443217277527\n",
      "batch: 1200, loss: 1.4033452272415161\n",
      "batch: 1300, loss: 1.4256715774536133\n",
      "batch: 1400, loss: 0.8383592367172241\n",
      "batch: 1500, loss: 0.7758926749229431\n",
      "batch: 1600, loss: 0.9061694741249084\n",
      "batch: 1700, loss: 1.4822871685028076\n",
      "batch: 1800, loss: 0.7045347690582275\n",
      "batch: 1900, loss: 0.6763896346092224\n",
      "batch: 2000, loss: 0.751266598701477\n",
      "batch: 2100, loss: 0.6989781260490417\n",
      "batch: 2200, loss: 0.5933015942573547\n",
      "batch: 2300, loss: 0.5696010589599609\n",
      "batch: 2400, loss: 0.7023036479949951\n",
      "batch: 2500, loss: 0.8953949213027954\n",
      "batch: 2600, loss: 1.3415123224258423\n",
      "batch: 2700, loss: 0.5017699003219604\n",
      "batch: 2800, loss: 1.0134526491165161\n",
      "batch: 2900, loss: 0.8731594681739807\n",
      "batch: 3000, loss: 1.0845201015472412\n",
      "batch: 3100, loss: 1.1260192394256592\n",
      "batch: 3200, loss: 1.1383171081542969\n",
      "batch: 3300, loss: 0.7873451709747314\n",
      "batch: 3400, loss: 0.6752835512161255\n",
      "batch: 3500, loss: 1.101912021636963\n",
      "batch: 3600, loss: 0.897704005241394\n",
      "batch: 3700, loss: 0.9942129850387573\n",
      "batch: 3800, loss: 1.524472951889038\n",
      "batch: 3900, loss: 0.7111269235610962\n",
      "batch: 4000, loss: 1.4102156162261963\n",
      "batch: 4100, loss: 1.1808457374572754\n",
      "batch: 4200, loss: 0.714664101600647\n",
      "batch: 4300, loss: 0.584931492805481\n",
      "batch: 4400, loss: 1.1241631507873535\n",
      "batch: 4500, loss: 1.0171101093292236\n",
      "batch: 4600, loss: 0.9479323029518127\n",
      "batch: 4700, loss: 0.7079033851623535\n",
      "batch: 4800, loss: 0.8292334675788879\n",
      "batch: 4900, loss: 0.7106766700744629\n",
      "batch: 5000, loss: 0.9124407172203064\n",
      "train_loss: 0.610776424407959\n",
      "Train Accuracy: 60.22%\n",
      "Test Accuracy: 57.25%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9db1974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'clip_mlp.pt')\n",
    "model = torch.load('clip_mlp.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f1cbbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46      3894\n",
      "           1       0.62      0.74      0.67      6489\n",
      "           2       0.62      0.38      0.47      4818\n",
      "\n",
      "    accuracy                           0.56     15201\n",
      "   macro avg       0.56      0.54      0.54     15201\n",
      "weighted avg       0.57      0.56      0.55     15201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e08696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "label_maps = ['neutral', 'negative', 'positive']\n",
    "confmat = confusion_matrix(actual_labels, predicted_labels)\n",
    "sns.heatmap(\n",
    "    confmat,\n",
    "    xticklabels=label_maps,\n",
    "    yticklabels=label_maps,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Purples'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0856c484",
   "metadata": {},
   "source": [
    "### 1-2 (Perceiver Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb224c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = CLIPProcessor.from_pretrained('openai/clip-vit-base-patch32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbfb948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "clip = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "clip.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cace3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset3(Dataset):\n",
    "    \n",
    "    def __init__(self, embed_model, data, processor):\n",
    "        self.data = data\n",
    "        self.processor = processor\n",
    "        self.embed_model = embed_model\n",
    "        self.embed_model.eval()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image, text, label = self.data[index]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            inputs = self.processor(\n",
    "                text=text,\n",
    "                images=image,\n",
    "                return_tensors='pt',\n",
    "                padding=True\n",
    "            )\n",
    "            output = self.embed_model(**inputs.to(device))\n",
    "            text_embeds = output.text_embeds\n",
    "            image_embeds = output.image_embeds\n",
    "            \n",
    "        concat_embeds = torch.concatenate((text_embeds, image_embeds), dim=1)\n",
    "        \n",
    "        return concat_embeds, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ca989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and test sets\n",
    "\n",
    "train_data = CustomDataset3(\n",
    "    data=train_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")\n",
    "\n",
    "test_data = CustomDataset3(\n",
    "    data=test_dataset_orig,\n",
    "    processor=processor,\n",
    "    embed_model=clip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5f5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config of the model\n",
    "\n",
    "config = PerceiverConfig()\n",
    "config.num_labels = 3\n",
    "config.d_model = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512fab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceiverClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.perceiver = PerceiverModel(\n",
    "            config=config,\n",
    "            decoder=PerceiverClassificationDecoder(\n",
    "                config,\n",
    "                num_channels=config.d_latents,\n",
    "                trainable_position_encoding_kwargs=dict(num_channels=config.d_latents, index_dims=1),\n",
    "                use_query_residual=True,\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        self.identity = nn.Identity()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.perceiver(x).logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc63215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a perceiver model\n",
    "perceiver_classifier = PerceiverClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3414fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 3e-5\n",
    "batch_size = 1\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aef0e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(perceiver_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fcd5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            num_correct += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc282d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.81 GiB total capacity; 2.53 GiB already allocated; 16.44 MiB free; 2.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperceiver_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     test_loop(test_dataloader, perceiver_classifier, loss_fn)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# back prop\u001b[39;00m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_num \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/DL/HWs/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.81 GiB total capacity; 2.53 GiB already allocated; 16.44 MiB free; 2.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, perceiver_classifier, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, perceiver_classifier, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4ec6c",
   "metadata": {},
   "source": [
    "### 2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "019601c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer for the bert model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a1520da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and text classifier\n",
    "image_classifier = torch.load('resnet50_phase1.pt').to(device)\n",
    "text_classifier = torch.load('bert_phase2.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f07ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OpenViDial(\n",
    "    data_path=pathlib.Path('./data/OpenViDial'),\n",
    "    image_transform=Compose([\n",
    "        Resize((64, 128)),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    text_transform=lambda x: tokenizer(\n",
    "        x,\n",
    "        padding='max_length',\n",
    "        max_length=100,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad17e6c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02858d57a1db46ab8973cfd5d1862f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting pseudo labels using text_classifier model\n",
    "batch_size = 16\n",
    "pseudo_labels = []\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "text_classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text, _ in tqdm(dataloader):\n",
    "        # Get logits for the text\n",
    "        mask = text['attention_mask'].to(device)\n",
    "        input_id = text['input_ids'].squeeze(1).to(device)\n",
    "        outputs = text_classifier(\n",
    "            input_ids=input_id,\n",
    "            attention_mask=mask,\n",
    "        )\n",
    "        \n",
    "        text_logits = outputs.logits\n",
    "        pseudo_labels.extend(nn.functional.softmax(text_logits, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ee308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom dataset for vision model learning\n",
    "\n",
    "class VisionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _, image = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea67aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split for vision dataset\n",
    "\n",
    "vision_dataset = VisionDataset(\n",
    "    data=dataset,\n",
    "    labels=pseudo_labels\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(vision_dataset))\n",
    "test_size = len(vision_dataset) - train_size\n",
    "train_set, test_set = random_split(vision_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ae6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the vision model using pseudo labels from the text model\n",
    "\n",
    "# define hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a43b25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function and dataloader\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(image_classifier.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e10c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        # forward prop\n",
    "        X = X.to(torch.float32).to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        num_correct += (y_pred.argmax(dim=1) == y.argmax(dim=1)).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_num % 100 == 0:\n",
    "            print(f'batch: {batch_num}, loss: {loss.item()}')\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'train_loss: {loss.item()}')\n",
    "    print(f'Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    \n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            X = X.to(torch.float32).to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(X)\n",
    "            predicted_labels.extend(y_pred.argmax(dim=1).cpu())\n",
    "            actual_labels.extend(y.argmax(dim=1).cpu())\n",
    "            num_correct += (y_pred.argmax(dim=1) == y.argmax(dim=1)).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bff87761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ==================================================\n",
      "batch: 0, loss: 1.046743631362915\n",
      "batch: 100, loss: 0.9483927488327026\n",
      "batch: 200, loss: 1.1409575939178467\n",
      "batch: 300, loss: 1.1154756546020508\n",
      "batch: 400, loss: 1.0654029846191406\n",
      "batch: 500, loss: 1.1086297035217285\n",
      "batch: 600, loss: 1.1371238231658936\n",
      "batch: 700, loss: 0.9810164570808411\n",
      "batch: 800, loss: 1.1206129789352417\n",
      "batch: 900, loss: 1.0935885906219482\n",
      "batch: 1000, loss: 1.145851492881775\n",
      "batch: 1100, loss: 1.128443956375122\n",
      "batch: 1200, loss: 1.0343799591064453\n",
      "batch: 1300, loss: 1.078305959701538\n",
      "batch: 1400, loss: 1.1239254474639893\n",
      "batch: 1500, loss: 1.0637221336364746\n",
      "batch: 1600, loss: 1.005671501159668\n",
      "batch: 1700, loss: 1.0937247276306152\n",
      "batch: 1800, loss: 1.1002235412597656\n",
      "batch: 1900, loss: 1.095305323600769\n",
      "batch: 2000, loss: 1.0909533500671387\n",
      "batch: 2100, loss: 1.0076854228973389\n",
      "batch: 2200, loss: 1.0802583694458008\n",
      "batch: 2300, loss: 1.128258466720581\n",
      "batch: 2400, loss: 0.9843389391899109\n",
      "batch: 2500, loss: 1.09238600730896\n",
      "batch: 2600, loss: 1.043968677520752\n",
      "batch: 2700, loss: 1.1002776622772217\n",
      "train_loss: 1.096634864807129\n",
      "Train Accuracy: 43.55%\n",
      "Test Accuracy: 44.13%\n",
      "\n",
      "epoch 2 ==================================================\n",
      "batch: 0, loss: 1.0290203094482422\n",
      "batch: 100, loss: 1.1057839393615723\n",
      "batch: 200, loss: 1.0786792039871216\n",
      "batch: 300, loss: 1.092588186264038\n",
      "batch: 400, loss: 1.0011019706726074\n",
      "batch: 500, loss: 1.110931396484375\n",
      "batch: 600, loss: 1.0109251737594604\n",
      "batch: 700, loss: 1.0161685943603516\n",
      "batch: 800, loss: 1.1210589408874512\n",
      "batch: 900, loss: 1.0836622714996338\n",
      "batch: 1000, loss: 1.0652707815170288\n",
      "batch: 1100, loss: 1.163419485092163\n",
      "batch: 1200, loss: 1.0510562658309937\n",
      "batch: 1300, loss: 1.1339411735534668\n",
      "batch: 1400, loss: 1.0656442642211914\n",
      "batch: 1500, loss: 1.0150105953216553\n",
      "batch: 1600, loss: 1.1007516384124756\n",
      "batch: 1700, loss: 1.078172206878662\n",
      "batch: 1800, loss: 1.0030957460403442\n",
      "batch: 1900, loss: 1.122985601425171\n",
      "batch: 2000, loss: 1.0160479545593262\n",
      "batch: 2100, loss: 1.190197467803955\n",
      "batch: 2200, loss: 1.0243983268737793\n",
      "batch: 2300, loss: 1.1180105209350586\n",
      "batch: 2400, loss: 1.1061314344406128\n",
      "batch: 2500, loss: 1.07708740234375\n",
      "batch: 2600, loss: 1.1566920280456543\n",
      "batch: 2700, loss: 1.0116374492645264\n",
      "train_loss: 0.9859577417373657\n",
      "Train Accuracy: 43.9%\n",
      "Test Accuracy: 44.38%\n",
      "\n",
      "epoch 3 ==================================================\n",
      "batch: 0, loss: 1.1150891780853271\n",
      "batch: 100, loss: 1.129910945892334\n",
      "batch: 200, loss: 1.1828839778900146\n",
      "batch: 300, loss: 1.0375555753707886\n",
      "batch: 400, loss: 1.1572544574737549\n",
      "batch: 500, loss: 1.0008682012557983\n",
      "batch: 600, loss: 1.0453691482543945\n",
      "batch: 700, loss: 1.0739552974700928\n",
      "batch: 800, loss: 1.0323807001113892\n",
      "batch: 900, loss: 1.0269944667816162\n",
      "batch: 1000, loss: 1.1099669933319092\n",
      "batch: 1100, loss: 1.0407201051712036\n",
      "batch: 1200, loss: 1.1090275049209595\n",
      "batch: 1300, loss: 1.0532647371292114\n",
      "batch: 1400, loss: 1.1038185358047485\n",
      "batch: 1500, loss: 1.0422898530960083\n",
      "batch: 1600, loss: 1.028967022895813\n",
      "batch: 1700, loss: 1.1028532981872559\n",
      "batch: 1800, loss: 1.0842978954315186\n",
      "batch: 1900, loss: 1.089709758758545\n",
      "batch: 2000, loss: 1.0336945056915283\n",
      "batch: 2100, loss: 1.0811359882354736\n",
      "batch: 2200, loss: 1.1005480289459229\n",
      "batch: 2300, loss: 1.1039421558380127\n",
      "batch: 2400, loss: 1.0546202659606934\n",
      "batch: 2500, loss: 1.137137532234192\n",
      "batch: 2600, loss: 1.0486633777618408\n",
      "batch: 2700, loss: 0.9896920919418335\n",
      "train_loss: 1.0711431503295898\n",
      "Train Accuracy: 44.07%\n",
      "Test Accuracy: 44.34%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'epoch {i}', '='*50)\n",
    "    train_loop(train_dataloader, image_classifier, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, image_classifier, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ab3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(image_classifier, 'domain_adaptation.pt')\n",
    "image_classifier = torch.load('domain_adaptation.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a17cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.06      0.10     10920\n",
      "           1       0.44      0.96      0.61     14724\n",
      "           2       0.00      0.00      0.00      7758\n",
      "\n",
      "    accuracy                           0.44     33402\n",
      "   macro avg       0.29      0.34      0.24     33402\n",
      "weighted avg       0.33      0.44      0.30     33402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33dc9d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "label_maps = ['neutral', 'negative', 'positive']\n",
    "confmat = confusion_matrix(actual_labels, predicted_labels)\n",
    "sns.heatmap(\n",
    "    confmat,\n",
    "    xticklabels=label_maps,\n",
    "    yticklabels=label_maps,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues'\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
